# ЭФМО-01-25 Буров М.А. ПР13

# Описание проекта
Профилирование Go-приложения (pprof). Измерение времени работы функций

# Требования к проекту
* Go 1.25+
* Git

# Версия Go
<img width="317" height="55" alt="image" src="https://github.com/user-attachments/assets/43f9087b-95b9-4c7d-86e9-746258c45c63" />

# Цели:
1.	Научиться подключать и использовать профилировщик pprof для анализа CPU, памяти, блокировок и горутин.
2.	Освоить базовые техники измерения времени выполнения функций (ручные таймеры, бенчмарки).
3.	Научиться читать отчёты go tool pprof, строить графы вызовов и находить “узкие места”.
4.	Сформировать практические навыки оптимизации кода на основании метрик.

# Краткое описание
Профилирование показывает, где тратятся CPU-циклы, память, где происходят блокировки, сколько активных горутин и т.п. Решает две задачи: (а) находить узкие места; (б) проверять, что оптимизация действительно помогает.

# Структура проекта
Дерево структуры проекта: 
```
pz13-pprof-lab/
├── cmd/
│   └── api/
│       └── main.go
├── internal/
│   ├── work/
│       ├── slow_test.go
│       ├── slow.go
│       └── timer.go
├── go.mod
└── README.md
```

# CPU-профиль

## До оптимизации

top:

<img width="682" height="249" alt="image" src="https://github.com/user-attachments/assets/28a373ae-2830-4ed2-8bd5-5e6c42fa5e72" />

graph/web:

<img width="684" height="816" alt="image" src="https://github.com/user-attachments/assets/11f03a6a-4d55-4241-9b93-200b5556aa1f" />

## После оптимизации

top:

<img width="587" height="239" alt="image" src="https://github.com/user-attachments/assets/3f562255-e145-409b-9075-4de5baf13de3" />

graph/web:

<img width="442" height="823" alt="image" src="https://github.com/user-attachments/assets/a403625c-885c-4f62-a0cd-c7826298a7f9" />

# Heap-профиль

## До оптимизации

<img width="577" height="228" alt="image" src="https://github.com/user-attachments/assets/bf673929-2bb8-4ea8-8abf-83e9c38a1804" />

<img width="447" height="860" alt="image" src="https://github.com/user-attachments/assets/f0007aa1-a657-415e-aa5d-e3c0484717eb" />

Кто именно аллоцирует память:
1. runtime.allocm — примерно 53% всей памяти

Это внутренний код Go, который выделяет служебные структуры и стеки для потоков.
То есть сюда уходит больше половины памяти, но это «служебные» аллокации рантайма, а не приложения.

2. compress/flate.NewWriter — примерно 47% памяти

Это код из стандартной библиотеки, который создаёт объект для сжатия данных (gzip/flate).
Он используется, когда net/http/pprof отдаёт профиль через HTTP, поэтому почти половина памяти — это временные буферы на стороне pprof.

3. Fib, обработчиков HTTP в top нет

Это значит, что они почти не делают heap‑аллокаций.

## После оптимизации

<img width="505" height="230" alt="image" src="https://github.com/user-attachments/assets/63548cc6-aa93-4e3a-b82b-49fdd91bab29" />

<img width="517" height="803" alt="image" src="https://github.com/user-attachments/assets/cd28b1fd-5db4-4b9a-8dac-6254182fa341" />

# Логи ручных таймеров и результаты бенчмарков

## До оптимизации

Логи ручных таймеров:

<img width="440" height="75" alt="image" src="https://github.com/user-attachments/assets/092030fb-0276-42a8-aa9b-68d925f93088" />

Результаты бенчмарка:

<img width="731" height="148" alt="image" src="https://github.com/user-attachments/assets/076aebd3-fcbc-4da3-aa69-4f8ca5a130b5" />

## После оптимизации

Логи ручных таймеров:

<img width="441" height="84" alt="image" src="https://github.com/user-attachments/assets/320b8541-72b6-451b-9bbe-aeaf78db8e3c" />

Результаты бенчмарка:

<img width="633" height="181" alt="image" src="https://github.com/user-attachments/assets/63dd6822-0ce4-49c1-82b1-6bcfad3e2f8c" />

# Описание оптимизации

Что оптимизировали:

Функция `Fib(n)` — рекурсивное вычисление чисел Фибоначчи.

**ДО (медленный вариант):**
```
func Fib(n int) int {
	if n < 2 {
		return n
	}
	return Fib(n-1) + Fib(n-2)  // ← Две рекурсивные ветки!
}
```

**ПОСЛЕ (быстрый вариант):**
```
func FibFast(n int) int {
	if n < 2 {
		return n
	}
	a, b := 0, 1
	for i := 2; i <= n; i++ {
		a, b = b, a+b  // ← Итерация, без рекурсии
	}
	return b
}
```

Почему это помогает:
Рекурсивный Fib — экспоненциальная сложность:

- Fib(38) вызывает ~50 млн функций
- Каждый вызов — проверка условия
- Стек вызовов растет до глубины 38
- Много дублирования вычислений (Fib(5) вычисляется 21 раз!)

Итеративный FibFast — линейная сложность:

- Fib(38) выполняется в 38 итераций
- Каждая итерация — 2 переменные и 1 операция
- Стек не растет
- Нет дублирования

# Сравнительная таблица метрик (до/после)

## Бенчмарки (Fib(30)):

| Параметр | До оптимизации (Fib) | После оптимизации (FibFast) |
|----------|---------------------|-----------------------------|
| **ns/op** | 7557095 ns | 21 ns |
| **B/op** | 0 B | 0 B |
| **allocs/op** | 0 | 0 |

## Логи таймеров (Fib(38)):

| Метрика | До оптимизации | После оптимизации |
|---------|----------------|-------------------|
| Время на запрос | ~3.5 сек | ~50 мкс |

# Выводы

## Узкое место:

Функция `Fib(n)` с рекурсивной реализацией потребляла:
- 94.5% процессорного времени (из CPU-профиля)
- Причина: экспоненциальная сложность O(2^n)
- Дублирование вычислений (Fib(5) → 21 раз)
- Большая глубина стека вызовов

## Что дала оптимизация:

1. Замена алгоритма: рекурсия → итерация
2. Сложность: O(2^n) → O(n) линейная
3. Результат: 450x ускорение при Fib(30)

## Метрики улучшения:

- Бенчмарки: 7557095 ns/op → 21 ns/op
- Логи: 3.5s → 50µs
  
# Ответы на контрольные вопросы

1.	Чем профилирование отличается от логирования и простых таймеров?

Профилирование (pprof) — это автоматический анализ программы, который показывает, где тратятся CPU-циклы, память, где происходят блокировки и сколько активных горутин. Решает две главные задачи:

(а) находить узкие места в коде

(б) проверять, что оптимизация действительно помогает

Логирование — это точечная информация, которую вы вручную добавляете в код. Видны только те места, где вы логировали.

Простые таймеры — это time.Now() перед и после функции. Дают только общее время, не показывают деталей распределения по функциям.

2.	Что показывает CPU-профиль и как его интерпретировать (top, list, graph)?

CPU profile

Показывает:
- Какие функции потребляют больше всего процессорного времени
- Сколько раз каждая функция была вызвана
- Из каких функций они вызываются (граф вызовов)

Интерпретация команд

**`top` — таблица функций по CPU времени:**
- `flat` — время в самой функции (без подвызовов)
- `flat%` — процент от общего времени
- `cum%` — кумулятивный процент
- `calls` — количество вызовов

**Интерпретация:** `main.Fib` потребляет 94.5% всего времени — это узкое место!

**`list Функция` — исходный код с метриками по строкам:**
- Показывает конкретные строки кода
- Красные/горячие строки — потребляют больше CPU

**`graph/web` — граф вызовов (визуализация):**
- Стрелки: кто кого вызывает
- Толщина стрелки = количество времени
- Размер блока = потребление CPU

3.	В чём разница allocs и inuse в Heap-профиле?

**Heap profile** показывает распределение по выделениям памяти:

inuse_space (inuse)

Сколько памяти удерживается СЕЙЧАС в момент снятия профиля.
- Если функция выделила 1MB, но потом освободила → inuse не считает
- Актуально для OOM (Out of Memory) ошибок

alloc_space (allocs)

Сколько памяти выделено ВСЕГО за время работы программы.
- Включает уже освобожденную память
- Суммарное количество всех аллокаций

4.	Как включить и для чего анализировать block и mutex профили?

Включение профилей

```
import "runtime"

func init() {
    runtime.SetBlockProfileRate(1)       // Block profile
    runtime.SetMutexProfileFraction(1)   // Mutex profile
}
```

Доступ к профилям

```
go tool pprof http://localhost:8080/debug/pprof/block
go tool pprof http://localhost:8080/debug/pprof/mutex
```

Block profile

**Для чего:** показывает где горутины простаивают, ожидая доступа к channel или синхронизации.

**Когда использовать:**
- Поиск deadlock'ов
- Анализ узких мест синхронизации
- Если производительность упадает на мощных CPU

Mutex profile

**Для чего:** показывает где горутины ждут освобождения mutex'а.

**Когда использовать:**
- Много конкурентного доступа к одному ресурсу
- Контенция (contention) на блокировках
- Оптимизация синхронизации

5.	Какие метрики дают бенчмарки testing.B, что означает ns/op, B/op, allocs/op?

Запуск бенчмарков

```
go test -bench=. -benchmem ./package
```

Метрики

| Метрика | Пример | Значение |
|---------|--------|----------|
| **BenchmarkFib-8** | — | Имя теста, 8 процессоров |
| **100000** | — | Количество итераций (b.N) |
| **ns/op** | 11250 | Время одной итерации в наносекундах (11.25 µs) |
| **B/op** | 0 | Байт выделено на одну итерацию (память) |
| **allocs/op** | 0 | Выделений памяти на одну итерацию |

6.	Почему важно сравнивать оптимизации на одинаковой нагрузке и фиксировать «до/после»?

**Разные нагрузки дают разные результаты**
   - На малых N может доминировать overhead
   - На больших N — cache misses
   - На очень больших — swapping в диск

**Нестабильность при разных временах**
   - 1ms тест = ошибка измерения ±10-20%
   - 100ms тест = ошибка ±1-2%

**Перегрев процессора**
   - Долгий бенч → CPU throttling
   - Результаты становятся нестабильными

Как правильно сравнивать

```
# ДО оптимизации
go test -bench=. -benchmem -count=5 ./package > before.txt

# (оптимизируете код)

# ПОСЛЕ оптимизации
go test -bench=. -benchmem -count=5 ./package > after.txt

# Сравниваете (если есть benchstat)
benchstat before.txt after.txt
```
   
7.	Какой порядок действий при поиске узкого места в производительности?

**Сначала ИЗМЕРЯЕМ** (базовые метрики)
**Интерпретируем отчёт** (hot path, тяжёлые аллокации, блокировки)
**Вносим МИНИМАЛЬНУЮ оптимизацию**, снова измеряем
**Фиксируем результат в отчёте** (до/после)
