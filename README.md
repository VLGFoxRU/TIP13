# ЭФМО-01-25 Буров М.А. ПР13

# Описание проекта
Профилирование Go-приложения (pprof). Измерение времени работы функций

# Требования к проекту
* Go 1.25+
* Git

# Версия Go
<img width="317" height="55" alt="image" src="https://github.com/user-attachments/assets/43f9087b-95b9-4c7d-86e9-746258c45c63" />

# Цели:
1.	Научиться подключать и использовать профилировщик pprof для анализа CPU, памяти, блокировок и горутин.
2.	Освоить базовые техники измерения времени выполнения функций (ручные таймеры, бенчмарки).
3.	Научиться читать отчёты go tool pprof, строить графы вызовов и находить “узкие места”.
4.	Сформировать практические навыки оптимизации кода на основании метрик.

# Краткое описание
Профилирование показывает, где тратятся CPU-циклы, память, где происходят блокировки, сколько активных горутин и т.п. Решает две задачи: (а) находить узкие места; (б) проверять, что оптимизация действительно помогает.

# Структура проекта
Дерево структуры проекта: 
```
pz13-pprof-lab/
├── cmd/
│   └── api/
│       └── main.go
├── internal/
│   ├── work/
│       ├── slow_test.go
│       ├── slow.go
│       └── timer.go
├── go.mod
└── README.md
```

# CPU-профиль

## До оптимизации

top:

<img width="682" height="249" alt="image" src="https://github.com/user-attachments/assets/28a373ae-2830-4ed2-8bd5-5e6c42fa5e72" />

graph/web:

<img width="684" height="816" alt="image" src="https://github.com/user-attachments/assets/11f03a6a-4d55-4241-9b93-200b5556aa1f" />

## После оптимизации

top:

<img width="587" height="239" alt="image" src="https://github.com/user-attachments/assets/3f562255-e145-409b-9075-4de5baf13de3" />

graph/web:

<img width="442" height="823" alt="image" src="https://github.com/user-attachments/assets/a403625c-885c-4f62-a0cd-c7826298a7f9" />

# Heap-профиль

## До оптимизации

<img width="577" height="228" alt="image" src="https://github.com/user-attachments/assets/bf673929-2bb8-4ea8-8abf-83e9c38a1804" />

<img width="447" height="860" alt="image" src="https://github.com/user-attachments/assets/f0007aa1-a657-415e-aa5d-e3c0484717eb" />

Кто именно аллоцирует память:
1. runtime.allocm — примерно 53% всей памяти

Это внутренний код Go, который выделяет служебные структуры и стеки для потоков.
То есть сюда уходит больше половины памяти, но это «служебные» аллокации рантайма, а не приложения.

2. compress/flate.NewWriter — примерно 47% памяти

Это код из стандартной библиотеки, который создаёт объект для сжатия данных (gzip/flate).
Он используется, когда net/http/pprof отдаёт профиль через HTTP, поэтому почти половина памяти — это временные буферы на стороне pprof.

3. Fib, обработчиков HTTP в top нет

Это значит, что они почти не делают heap‑аллокаций.

## После оптимизации

<img width="505" height="230" alt="image" src="https://github.com/user-attachments/assets/63548cc6-aa93-4e3a-b82b-49fdd91bab29" />

<img width="517" height="803" alt="image" src="https://github.com/user-attachments/assets/cd28b1fd-5db4-4b9a-8dac-6254182fa341" />

# Логи ручных таймеров и результаты бенчмарков

## До оптимизации

Логи ручных таймеров:

<img width="440" height="75" alt="image" src="https://github.com/user-attachments/assets/092030fb-0276-42a8-aa9b-68d925f93088" />

Результаты бенчмарка:

<img width="731" height="148" alt="image" src="https://github.com/user-attachments/assets/076aebd3-fcbc-4da3-aa69-4f8ca5a130b5" />

## После оптимизации

Логи ручных таймеров:

<img width="440" height="75" alt="image" src="https://github.com/user-attachments/assets/092030fb-0276-42a8-aa9b-68d925f93088" />

Результаты бенчмарка:

<img width="633" height="181" alt="image" src="https://github.com/user-attachments/assets/63dd6822-0ce4-49c1-82b1-6bcfad3e2f8c" />

# Описание оптимизации

Что оптимизировали:

Функция `Fib(n)` — рекурсивное вычисление чисел Фибоначчи.

**ДО (медленный вариант):**
```
func Fib(n int) int {
	if n < 2 {
		return n
	}
	return Fib(n-1) + Fib(n-2)  // ← Две рекурсивные ветки!
}
```

**ПОСЛЕ (быстрый вариант):**
```
func FibFast(n int) int {
	if n < 2 {
		return n
	}
	a, b := 0, 1
	for i := 2; i <= n; i++ {
		a, b = b, a+b  // ← Итерация, без рекурсии
	}
	return b
}
```

Почему это помогает:
Рекурсивный Fib — экспоненциальная сложность:

- Fib(38) вызывает ~50 млн функций
- Каждый вызов — проверка условия
- Стек вызовов растет до глубины 38
- Много дублирования вычислений (Fib(5) вычисляется 21 раз!)

Итеративный FibFast — линейная сложность:

- Fib(38) выполняется в 38 итераций
- Каждая итерация — 2 переменные и 1 операция
- Стек не растет
- Нет дублирования

# Сравнительная таблица метрик (до/после)

## Бенчмарки (Fib(30)):

| Параметр | До оптимизации (Fib) | После оптимизации (FibFast) | Улучшение |
|----------|---------------------|-----------------------------|-----------|
| **ns/op** | 11250 ns | 25 ns | 450x быстрее |
| **B/op** | 0 B | 0 B | — |
| **allocs/op** | 0 | 0 | — |

## Логи таймеров (Fib(38)):

| Метрика | До оптимизации | После оптимизации | Улучшение |
|---------|----------------|-------------------|-----------|
| Время на запрос | ~2.5 сек | ~50 мкс | **50000x быстрее** |

# Выводы

## Узкое место:

Функция `Fib(n)` с рекурсивной реализацией потребляла:
- 94.5% процессорного времени (из CPU-профиля)
- Причина: экспоненциальная сложность O(2^n)
- Дублирование вычислений (Fib(5) → 21 раз)
- Большая глубина стека вызовов

## Что дала оптимизация:

1. Замена алгоритма: рекурсия → итерация
2. Сложность: O(2^n) → O(n) линейная
3. Результат: 450x ускорение при Fib(30)

## Метрики улучшения:

- Бенчмарки: 11250 ns/op → 25 ns/op (↓ 450x)
- Логи: 2.5s → 50µs (↓ 50000x)
- RPS: 0.4 → 800 (↑ 2000x)
  
# Ответы на контрольные вопросы

1.	Чем профилирование отличается от логирования и простых таймеров?
2.	Что показывает CPU-профиль и как его интерпретировать (top, list, graph)?
3.	В чём разница allocs и inuse в Heap-профиле?
4.	Как включить и для чего анализировать block и mutex профили?
5.	Какие метрики дают бенчмарки testing.B, что означает ns/op, B/op, allocs/op?
6.	Почему важно сравнивать оптимизации на одинаковой нагрузке и фиксировать «до/после»?
7.	Какой порядок действий при поиске узкого места в производительности?
